{"ast":null,"code":"// src/utils/gptApi.js\nexport const callGptWithPrompt = async prompt => {\n  const system_prompt = `B·∫°n l√† m·ªôt tr·ª£ l√Ω du l·ªãch th√¥ng minh. V·ªõi m·ªói c√¢u h·ªèi, h√£y:\n1. Ki·ªÉm tra v√† cung c·∫•p th√¥ng tin d·ª± b√°o th·ªùi ti·∫øt ch√≠nh x√°c c·ªßa ƒë·ªãa ƒëi·ªÉm v√† ng√†y ƒë∆∞·ª£c h·ªèi.\n2. D·ª±a v√†o th·ªùi ti·∫øt ƒë√≥, ƒë∆∞a ra c√°c g·ª£i √Ω th·ª±c t·∫ø theo c·∫•u tr√∫c sau (ng·∫Øn g·ªçn, r√µ r√†ng, ‚â§200 tokens):\n\nüå§ D·ª± b√°o th·ªùi ti·∫øt: [th√¥ng tin th·ªùi ti·∫øt ch√≠nh x√°c ng√†y h√¥m ƒë√≥ t·∫°i ƒë·ªãa ƒëi·ªÉm]\nüéØ G·ª£i √Ω ho·∫°t ƒë·ªông: [ho·∫°t ƒë·ªông ph√π h·ª£p, n·∫øu th·ªùi ti·∫øt x·∫•u th√¨ khuy√™n kh√¥ng camping]\nüéí Danh s√°ch v·∫≠t d·ª•ng: [nh·ªØng ƒë·ªì c·∫ßn mang theo, ph√π h·ª£p th·ªùi ti·∫øt]\n‚ö†Ô∏è L∆∞u √Ω ƒë·∫∑c bi·ªát: [c·∫£nh b√°o ho·∫∑c l∆∞u √Ω an to√†n, s·ª©c kh·ªèe, giao th√¥ng]`;\n  try {\n    var _data$choices, _data$choices$, _data$choices$$messag;\n    const response = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        Authorization: `Bearer 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` // thay key c·ªßa b·∫°n\n      },\n      body: JSON.stringify({\n        model: \"gpt-4o-mini\",\n        // ho·∫∑c \"gpt-4o\" n·∫øu b·∫°n c√≥ quy·ªÅn\n        messages: [{\n          role: \"system\",\n          content: system_prompt\n        }, {\n          role: \"user\",\n          content: prompt\n        }],\n        max_tokens: 500,\n        temperature: 0.7\n      })\n    });\n    if (!response.ok) {\n      const text = await response.text();\n      throw new Error(`L·ªói GPT: ${response.status} - ${text}`);\n    }\n    const data = await response.json();\n    return (data === null || data === void 0 ? void 0 : (_data$choices = data.choices) === null || _data$choices === void 0 ? void 0 : (_data$choices$ = _data$choices[0]) === null || _data$choices$ === void 0 ? void 0 : (_data$choices$$messag = _data$choices$.message) === null || _data$choices$$messag === void 0 ? void 0 : _data$choices$$messag.content) || \"Kh√¥ng c√≥ ph·∫£n h·ªìi.\";\n  } catch (error) {\n    console.error(\"GPT API error:\", error);\n    throw error;\n  }\n};","map":{"version":3,"names":["callGptWithPrompt","prompt","system_prompt","_data$choices","_data$choices$","_data$choices$$messag","response","fetch","method","headers","Authorization","body","JSON","stringify","model","messages","role","content","max_tokens","temperature","ok","text","Error","status","data","json","choices","message","error","console"],"sources":["D:/Project_EXE/client/src/utils/gptApi.js"],"sourcesContent":["// src/utils/gptApi.js\r\nexport const callGptWithPrompt = async (prompt) => {\r\n  const system_prompt = `B·∫°n l√† m·ªôt tr·ª£ l√Ω du l·ªãch th√¥ng minh. V·ªõi m·ªói c√¢u h·ªèi, h√£y:\r\n1. Ki·ªÉm tra v√† cung c·∫•p th√¥ng tin d·ª± b√°o th·ªùi ti·∫øt ch√≠nh x√°c c·ªßa ƒë·ªãa ƒëi·ªÉm v√† ng√†y ƒë∆∞·ª£c h·ªèi.\r\n2. D·ª±a v√†o th·ªùi ti·∫øt ƒë√≥, ƒë∆∞a ra c√°c g·ª£i √Ω th·ª±c t·∫ø theo c·∫•u tr√∫c sau (ng·∫Øn g·ªçn, r√µ r√†ng, ‚â§200 tokens):\r\n\r\nüå§ D·ª± b√°o th·ªùi ti·∫øt: [th√¥ng tin th·ªùi ti·∫øt ch√≠nh x√°c ng√†y h√¥m ƒë√≥ t·∫°i ƒë·ªãa ƒëi·ªÉm]\r\nüéØ G·ª£i √Ω ho·∫°t ƒë·ªông: [ho·∫°t ƒë·ªông ph√π h·ª£p, n·∫øu th·ªùi ti·∫øt x·∫•u th√¨ khuy√™n kh√¥ng camping]\r\nüéí Danh s√°ch v·∫≠t d·ª•ng: [nh·ªØng ƒë·ªì c·∫ßn mang theo, ph√π h·ª£p th·ªùi ti·∫øt]\r\n‚ö†Ô∏è L∆∞u √Ω ƒë·∫∑c bi·ªát: [c·∫£nh b√°o ho·∫∑c l∆∞u √Ω an to√†n, s·ª©c kh·ªèe, giao th√¥ng]`;\r\n\r\n  try {\r\n    const response = await fetch(\"https://api.openai.com/v1/chat/completions\", {\r\n      method: \"POST\",\r\n      headers: {\r\n        \"Content-Type\": \"application/json\",\r\n        Authorization: `Bearer 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`, // thay key c·ªßa b·∫°n\r\n      },\r\n      body: JSON.stringify({\r\n        model: \"gpt-4o-mini\", // ho·∫∑c \"gpt-4o\" n·∫øu b·∫°n c√≥ quy·ªÅn\r\n        messages: [\r\n          { role: \"system\", content: system_prompt },\r\n          { role: \"user\", content: prompt },\r\n        ],\r\n        max_tokens: 500,\r\n        temperature: 0.7,\r\n      }),\r\n    });\r\n\r\n    if (!response.ok) {\r\n      const text = await response.text();\r\n      throw new Error(`L·ªói GPT: ${response.status} - ${text}`);\r\n    }\r\n\r\n    const data = await response.json();\r\n    return data?.choices?.[0]?.message?.content || \"Kh√¥ng c√≥ ph·∫£n h·ªìi.\";\r\n  } catch (error) {\r\n    console.error(\"GPT API error:\", error);\r\n    throw error;\r\n  }\r\n};\r\n"],"mappings":"AAAA;AACA,OAAO,MAAMA,iBAAiB,GAAG,MAAOC,MAAM,IAAK;EACjD,MAAMC,aAAa,GAAG;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE;EAErE,IAAI;IAAA,IAAAC,aAAA,EAAAC,cAAA,EAAAC,qBAAA;IACF,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,4CAA4C,EAAE;MACzEC,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE,kBAAkB;QAClCC,aAAa,EAAE,6KAA6K,CAAE;MAChM,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBC,KAAK,EAAE,aAAa;QAAE;QACtBC,QAAQ,EAAE,CACR;UAAEC,IAAI,EAAE,QAAQ;UAAEC,OAAO,EAAEf;QAAc,CAAC,EAC1C;UAAEc,IAAI,EAAE,MAAM;UAAEC,OAAO,EAAEhB;QAAO,CAAC,CAClC;QACDiB,UAAU,EAAE,GAAG;QACfC,WAAW,EAAE;MACf,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACb,QAAQ,CAACc,EAAE,EAAE;MAChB,MAAMC,IAAI,GAAG,MAAMf,QAAQ,CAACe,IAAI,CAAC,CAAC;MAClC,MAAM,IAAIC,KAAK,CAAC,YAAYhB,QAAQ,CAACiB,MAAM,MAAMF,IAAI,EAAE,CAAC;IAC1D;IAEA,MAAMG,IAAI,GAAG,MAAMlB,QAAQ,CAACmB,IAAI,CAAC,CAAC;IAClC,OAAO,CAAAD,IAAI,aAAJA,IAAI,wBAAArB,aAAA,GAAJqB,IAAI,CAAEE,OAAO,cAAAvB,aAAA,wBAAAC,cAAA,GAAbD,aAAA,CAAgB,CAAC,CAAC,cAAAC,cAAA,wBAAAC,qBAAA,GAAlBD,cAAA,CAAoBuB,OAAO,cAAAtB,qBAAA,uBAA3BA,qBAAA,CAA6BY,OAAO,KAAI,oBAAoB;EACrE,CAAC,CAAC,OAAOW,KAAK,EAAE;IACdC,OAAO,CAACD,KAAK,CAAC,gBAAgB,EAAEA,KAAK,CAAC;IACtC,MAAMA,KAAK;EACb;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}